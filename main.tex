\documentclass{sig-alternate}
\usepackage[utf8]{inputenc}
\usepackage{times}
\usepackage{gensymb}
\usepackage{epsfig}
\usepackage{xcolor}

\begin{document}
\conferenceinfo{CIDR '17}{January 8-11, 2017, Santa Cruz, CA, USA}
\newcommand{\smallitem}[1]{\vspace{1em}\noindent\textbf{#1}}
\newcommand{\smallitembot}{\vspace{1em}\noindent}
\bibliographystyle{abbrv}

\newcommand{\jmh}[1]{{\textcolor{red}{[[#1 -- jmh]]}}}
\newcommand{\vikram}[1]{{\textcolor{blue}{[[#1 --vikram]]}}}
% \newcommand{\jmh}[1]{}



\title{Grounding Big Data with Data Context Services}
\numberofauthors{3}
\author{
Groundlings
}

\maketitle

\begin{abstract}
Ground is an open-source data context service, motivated by our experiences in the Big Data ecosystem. By data context, we refer to all the peripheral information that informs the use of data, going well beyond traditional metadata.
The way we use data has changed both philosophically and practically in the last decade, creating an opportunity for new data context services to foster further innovation in Big Data systems and applications. We provide motivation and design guidelines, present our initial design of a common metamodel and API, and explore the current state of the storage solutions that could serve the needs of a data context service. Throughout, we highlight opportunities for new research and engineering solutions.
\end{abstract}

\section{From Metadata to Context}
The open-source Big Data movement, spearheaded by Apache Hadoop, is often discussed in terms of changes in usage: the ``three V's'' of data being captured and the agile working style typified by ``schema-on-use'' and polyglot programming models.

Much less widely discussed is a profound shift toward a decoupled software architecture. Traditionally, database systems were consumed as monolithic stacks of component functionality, regardless of how well-factored they were under the covers. A DBMS included a consistent storage engine, a metadata catalog, a dataflow engine, a language compiler and optimizer, an execution scheduler/runtime, and facilities for data ingest and queueing. In today's Big Data stack, nearly all of these components are independent and swappable. Moreover, there are multiple choices for most of these components in wide use today. The decoupled architecture is healthy for innovation and specialization, and has been embraced by both developers and customers.

One negative side-effect of this diversity is the lack of an agreed-upon service to register metadata for these components. The only widely-used solution is the Hive Metastore, which serves simple relational schemas---a dead end for Variety. As a result, most ``Data Lake'' projects lack even the most basic information; typically it is not even possible to discover what is being stored. 
For emerging Big Data customers and vendors, this Big Metadata problem is hitting a crisis point.  Two serious problems emerge.

The first is poor productivity.
%The promise of the Data Lake is that a diversity of data can be easily captured, and then harnessed by analysts for value. 
In the absence of metadata, analysts are often unable to discover what data exists, much less how it may have been previously parsed, structured, cleansed and analyzed by peers. ``Tribal knowledge'' in an organization is the standard method for disseminating this information today. Clearly this does not scale, leading to wasted work and lost opportunities for analysts to build on the data and analysis known to others.

The second problem is governance risk. Data management necessarily entails recording governance information: who accesses data, what they do with it, where they put it, and how it gets consumed downstream. 
%In some cases this governance metadata is used to enforce policy (e.g.\ access control for Personally Identifiable Information); in others it is logged to support audits for compliance (e.g.\ in the Basel Committee on Banking Supervision). 
In the absence of a standard place to store and access this information, it is impossible to enforce policies and/or audit behavior. As a result, many administrators marginalize their Big Data stack as a playpen for non-sensitive data.

In our diverse experiences in industry, the authors have seen a pressing need for a common service layer to let Big Data components ``write down'' and share metadata information in a flexible way. The effort in this paper began by addressing that need.

\subsection{Metadata Crisis? Context Opportunity.}
The lack of a Big Data metadata service is not just a crisis; it is also a clean-slate opportunity to rethink design and usage. Storage economics and the simplicity of schema-on-use suggest that the Data Lake movement could go much farther than Data Warehouses in enabling diverse, widely-used central repositories of data.  If we view metadata more broadly, could a unified solution address a much broader set of goals than Data Warehouses? We can explore that notion along three axes:

\smallitem{Data.} A schema-on-use world is inherently relativistic. Data does not have \emph{inherent} structure and meaning; rather, the structure is imposed post hoc---sometimes for general usage, sometimes for a specific task.  This means that the ``description'' of a collection of data depends not only on its original form, but on the (many) ways it is transformed for use over time.  

\smallitem{Code}. Data is transformed by code, which becomes a necessary aspect of data description. Transformation is only one kind of data-centric code. There is also code that produces new data: analysis routines, statistical models, and outbound services like recommenders and ad systems. Data \emph{lineage} is a natural byproduct of code, relating it to data sources and outputs. Code also brings along data of its own: training data, model parameters, configuration files, etc. This is not the data of record in an organization; it is an aspect of the code itself. Code management brings its own requirements, notably information on versions, authors and testing.  
%With code and data versioned over time we can envision robust reproducibility of experiments---a feature of interest in areas including hypothesis testing (e.g. A/B tests) and in scientific verification.  

\smallitem{Usage}. In modern agile analytic environments, iterations of exploration, experimentation and (re)deployment of automated pipelines are daily activity. Ironically, today's Big Data software is not well-designed for enabling analysis of its own use. If people learn by doing, then the tribal knowledge of an analytic organization should be visible in its usage logs. Intelligent analytic software could take great advantage of these logs to augment and accelerate human activity and intelligence. Like all software usage logs, analytics logs are themselves big, diverse data.

\smallitembot
The enhanced functionality needed for this layer of the modern Big Data stack goes well beyond traditional metadata management. We refer to it as \emph{Data Context} services. Context refers to the full gamut of peripheral information that informs your analysis: what data and code do you have, where is it stored, when does it get used, who knows about it, and how does it change over time?  

\section{Ground: Scenarios and Design}
We are building an open-source data context service we call \emph{Ground}---a foundation for the broad data context agenda sketched above. 
The goal of Ground is to serve as a central model, API and repository for capturing the broad context in which data gets used. In designing Ground, our intent is to address practical problems for the Big Data community in the short term, and open up opportunities for research and innovation as well.

\subsection{Scenarios}
To illustrate the benefits of data context, consider the following scenario. It is only modestly futuristic: there are applications that do some of these things today, but could do far more if they had access to broader context.

\jmh{\textbf{Idea 1: Intelligent Business Intelligence.}}  Janet, an analyst at a major bank, believes that customers' social network behavior can help explain their likelihood of closing their account (churning). Evaluating this hypothesis requires a pipeline of stages: data acquisition, transformation and analysis. 
% Intelligent applications are emerging for each of these tasks today, which make suggestions to users. All could benefit from a more comprehensive service for data context, as we illustrate below.

Janet 
% plans to purchase a social media ``firehose'' feed for her analysis. To start, though, she 
begins by downloading a small sample of a social media feed from a free API into the data lake. Her data catalog application searches the context service for previously-defined schemas and data sketches, and notifies her that the data lake has a similar feed from the previous month. 
% Looking at that data, she finds it sufficient for her purposes; no need to pay for another feed. 
She then begins using the application to search the context service for historical data on customer churn: what is available, and who has access to it?  As she explores candidate schemas and data samples, the application looks up usage data in the context service and notifies Janet that one of her colleagues has access to many of these datasets, and has previously joined one of them with weather data. Janet decides to start with that dataset as well, and compare notes with her colleague later on.  
% In this scenario, the catalog application was particularly successful because it had access to broad context: not just a large corpus of raw data, but structured schemas for transformed versions of that data based on prior (schema-on-)use, as well as usage data capturing relationships between users, data and actions.

Once Janet chooses particular datasets to focus on, she begins to prepare them for analysis using a data wrangling application. As is typical, the social media feed is semi-structured and deeply nested; the wrangling application searches the context store for previous scripts on similarly-structured data, and suggests unnesting attributes and pivoting them into tabular form.  Recognizing location data in Janet's dataset, the application then consults a geo-reference data in the context store and makes her aware that many of the GPS locations in her data set are very far from any of the bank's branches, and may be candidates for cleaning. The application looks at type-specific analysis routines in the context store, and suggests to Janet that she can generate new columns derived from the social text using code for entity extraction and sentiment analysis written by her data science colleagues. Based on security information in the context service, Janet is warned that certain attributes of the customer churn data were marked confidential by another analyst, and should perhaps be masked. Finally, when she is ready to join the social media names against the bank customer names, the application uses information learned from previous transformation scripts to identify and standardize the join keys appropriately. 
% While the data wrangling application could have made some of these suggestions based on intrinsic properties of the data being transformed, it benefited substantially from peripheral context on other datasets and scripts. 
% : reference data like geographic distributions of branches, repositories of data science routines, and the analytic context that the datasets being wrangled came from the data lake with security annotations. \emph{Would be nicer to get an analytic context about Janet's behavior.}

Armed with a tidy table of hundreds of columns joined together, Janet opens her chosen BI charting application. She plans to cube the data set along various features of users and social media behavior, assessing churn rates in different categories. Given the richness of her wrangled table, the resulting number of potential charts is enormous. Fortunately her BI tool has automated features to recommend charts of interest. Using training data from many other analysts stored in the context service, the recommender focuses on breaking down the data on the custom, algorithmically-extracted sentiment scores and bank-specific entity features, as well as time and space; it omits customer names and the attributes marked confidential.  Janet notices a subcategory of posts with hate speech, and the BI tool enables her to highlight that category and store annotations on the related customers in the context service.
% Here again the BI tool benefits from broad context: lineage from the data wrangling application identifying algorithmic results, metadata on masking from the catalog tool, and training data on chart selection.
% ; these tools use intrinsic properties of their input data today~\cite{jeffheer}. To work better, they could benefit from the lineage of transformations that created their input---in our case recognizing the presence of social media data at the source, and recommending charts that were chosen for visualizing other outputs of social media datasets.
%If interesting patterns emerge in the data visualizations, the analyst may recommend decisions to the organization: e.g. to deploy customer service representatives to respond on social media, or to have the data science team incorporate social media feeds into more sophisticated predictive models for churn.

All of these tools use data context to provide Janet with assistance. Some features save her time on the task she is directly attempting; others provide her contextual information outside her core task---algorithmic ``tribal wisdom''. While some of these features can be provided by current applications that save and learn from their own metadata, all of them benefit substantially from a broader context that spans across applications. Note the ad-hoc, cyclic dependencies in this ``pipeline'': the catalog tool depends on the schemas and sketches generated by users wrangling data (schema-on-use!), the wrangling tool depends on the catalog tool, the BI tool benefits from the lineage of wrangling scripts and populates annotations that can be surfaced back in the catalog.

% \emph{A number of new applications for data analysts have begun to capture data context and provide assistive intelligence as described above, but they currently have no way to share that information.  Hence the scope of their context is limited to what they see at their inputs. Broadly-adopted data context services are key to expanding the intelligence of these applications, harnessing data and computation to improve analyst productivity.}


\jmh{\textbf{Idea 2: Model training and serving.  Joey to fill in? Or borrow a scenario from Johann's paper.} 
% The previous example focused on relatively simple exploratory data analysis. 
Data context can bring similar benefits to the kinds of predictive services that hardcore data scientists build and deploy live in modern hosted applications.  Large-scale predictive services like recommender systems and driving instructions rely on data scientists and engineers working in agile development cycles.  The services are based on serving results from models; the models themselves are periodically trained off of features extracted from data. Data and features evolve over time. Meanwhile, there should be a virtuous cycle of model training, serving and experimentation.  Want to improve this cycle. Want to be able to run new models on old traces (cite Johann's paper). Want to incorporate new models in debug mode in production. Want to be able to reward staff for improving models. Want to reallocate staff when the benefit of experimenting with the model no longer justifies the effort.}

\jmh{\textbf{Idea 3: A Pragmatic example in existing Hadoop workflows.  LinkedIn or Navigator customer story?}  Maybe take Idea 1 and make it less about assistive features, more about lost lineage across HDFS, Trifacta, Hive and Tableau?}

\subsection{Design Requirements}
In a decoupled architecture of multiple applications and backend services, context serves as a ``narrow waist'': a single point of access for the basic information about data and its usage. However, the use of data context remains an open-ended design opportunity. Hence we were keen to focus on simple decisions today that could enable the success of new services and applications in future. To this end we were guided by Postel's Law from Internet architecture: ``Be conservative in what you do, be liberal in what you accept from others''.  With this theme in hand, we identified four key design requirements for a successful data context service.

\smallitem{Model-Agnostic.} For a data context service to be broadly adopted, it cannot impose opinions on metadata modeling. Data models evolve over time, and essentially never die: modern organizations have to manage everything from COBOL data layouts to RDBMS dumps to XML, JSON, Apache logs and free text. As a result, the context service cannot prescribe how metadata is modeled---each dataset may have different metadata to manage. This is a significant weakness in the Big Data stack today: the Hive Metastore captures fixed features or relational schemas; HDFS captures fixed features of files.  A key challenge in Ground is to design a core metamodel that captures generic information that applies to all data, as well as custom information for different data models, applications, and usage. We explore this issue in Section~\ref{sec:metamodel}.

\smallitem{Immutable.} Data context must be immutable; ``updating'' stored context is tantamount to erasing history. Indeed, Postel's Law essentially dictates that we never discard information, lest somebody ask for it. There are multiple reasons why history is critical. The latest context may not always be the most relevant: we may want to replay scenarios from the past for what-if analysis or debugging, or study how context information (say, success rates of a statistical model) change over time. Prior context may also be important for governance and veracity purposes: we may be asked to audit historical behavior and metadata, or reproduce experimental results published in the past. This simplifies record-keeping, but of course it raises significant engineering challenges.  Mature storage solutions in the Big Data ecosystem do not support immutability and versioning natively. \vikram{I feel like a lot of peoples' first response to this is going to be "What about HDFS?" We may want to rephrase a little bit.} We explore this issue in Section~\ref{sec:storage}.

\smallitem{Scalable.} It is a frequent misconception that metadata is small. In fact, metadata scaling was already a challenge in previous-generation technology. In many Big Data settings, it is reasonable to envision the data context being far larger than the data itself. Usage information is one culprit: the logs from a data service can often outstrip the live data managed by the service. Another is the aforementioned desire for immutability: version history can be substantial. Finally, data lineage can also grow to be extremely large
%, depending on the kind of lineage desired
~\cite{cheney2009provenance}.  Of course it is possible to argue that various forms of context information should be managed as ``real data''.  Our main point here is that the use of a context service will encompass analyses and lookups over that information.  We explore these issues in Section~\ref{sec:storage} as well.

\smallitem{Politically Neutral.}  While not a design requirement per se, we note that any narrow-waist service like data context has to ``be Switzerland to be successful''.  Customers will only adopt a central data context service if they feel no fear of lock-in; application writers will prioritize support for widely-used APIs to maximize the benefit of their efforts. 
% Vendor-centric metadata and governance solutions in this space have traditionally raised concerns on those fronts; this is perhaps one reason why the traditional Master Data Management vendors have not been successful in the Big Data market. 
It is important to note here that \emph{open source is not equivalent to political neutrality}; customers and developers have to believe that the project leadership has strong incentives to behave in the common interest. We return to this point in Section~\ref{sec:discussion}.

\vspace{1em}
\jmh{Closing remark here on how these issues make things very interesting indeed!}

\section{Architecture of Ground}
\label{sec:arch}
\begin{figure*}[th]
\center
\includegraphics[width=0.7\linewidth]{groundarch.pdf}
\end{figure*}

\subsection{Common Ground: A Metamodel}
\label{sec:metamodel}
\subsection{Underground Services}

\section{Storage: A Prototype Evaluation}
\label{sec:storage}
Scenarios:
\begin{itemize}
\item Relational: Apiary
\item Code: Grit
\item Logs: Grunk
\end{itemize}

Functionality:
\begin{itemize}
\item transitive closure
\item point lookup
\item sessionization and trends?
\end{itemize}

Performance/Scale.

\section{Discussion}
\label{sec:discussion}
\jmh{This may evolve into Research Opportunities or Future Work, but this is a placeholder for things that were postponed in earlier text}

\jmh{Backref to Scalability discussion above, and the question ``are logs data or metadata''?}
LinkedIn WhereHows, FINRA Herd, 
Functionality: well, we've started building out a few things and they went well.  Apiary and Grit.

What about performance? Here we ran into some bottlenecks with the widely-used storage systems in the field.  This merits more attention.

\subsection{Initial Results}
\label{sec:perf}
\section{Challenges for the community}
\label{sec:challenges}
\section{Related Work}
\label{sec:relwork}
Old-school MDM. Cloudera Navigator, Apache Atlas, LinkedIn WhereHows, FINRA Herd, Google Goods, IBM LabBook. Host of research on graph queries/DBs. Immutable DBs: Postgres, Datomic, Pachyderm.io, Noms. ReproZip and Burrito for capturing lineage.
\section{Conclusion}
\label{sec:conclusion}
\bibliography{ground}
\end{document}
