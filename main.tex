\documentclass{sig-alternate}
\usepackage[utf8]{inputenc}
\usepackage{times}
\usepackage{gensymb}
\usepackage{epsfig}
\usepackage{xcolor}
\usepackage{xspace}
\usepackage{multicol}
\usepackage{listings}
\usepackage{verbatim}

\usepackage[protrusion=true,expansion=true]{microtype}
\setlength{\emergencystretch}{3em}



\begin{document}
\conferenceinfo{CIDR '17}{January 8-11, 2017, Santa Cruz, CA, USA}
\newcommand{\smallitem}[1]{\vspace{1em}\noindent\textbf{#1}}
\newcommand{\smallitembot}{\vspace{1em}\noindent}
\bibliographystyle{abbrv}

\newcommand{\jmh}[1]{{\textcolor{red}{[[#1 -- jmh]]}}}
\newcommand{\joey}[1]{{\textcolor{cyan}{[[#1 -- jeg]]}}}
\newcommand{\msd}[1]{{\textcolor{green}{[[#1 -- msd]]}}}
\newcommand{\akon}[1]{{\textcolor{orange}{[[#1 -- akon]]}}}

\newcommand{\vikram}[1]{{\textcolor{blue}{[[#1 --vikram]]}}}
% \newcommand{\jmh}[1]{}

% \newcommand{\cab}{CAB\xspace}
\newcommand{\core}{version graph\xspace}
\newcommand{\mantle}{model graph\xspace}
\newcommand{\crust}{lineage graph\xspace}
\newcommand{\Core}{Version Graph\xspace}
\newcommand{\Mantle}{Model Graph\xspace}
\newcommand{\Crust}{Lineage Graph\xspace}

\newcommand{\version}{\kw{Version}\xspace}
\newcommand{\richversion}{\kw{RichVersion}\xspace}
\newcommand{\thing}{\kw{Item}\xspace}
\newcommand{\node}{\kw{Node}\xspace}
\newcommand{\edge}{\kw{Edge}\xspace}
\newcommand{\structure}{\kw{Structure}\xspace}
\newcommand{\graph}{\kw{Graph}\xspace}
\newcommand{\TVID}{\kw{TVID}\xspace}
\newcommand{\gtag}{\kw{Tag}\xspace}
\newcommand{\uri}{\kw{URI}\xspace}

\newcommand{\versiongraph}{versiongraph\xspace}
\newcommand{\modelgraph}{modelgraph\xspace}
\newcommand{\lineagegraph}{lineagegraph\xspace}
\newcommand{\versiongraphs}{versiongraphs\xspace}
\newcommand{\modelgraphs}{modelgraphs\xspace}
\newcommand{\lineagegraphs}{lineagegraphs\xspace}
\newcommand{\groundwire}{GroundWire\xspace}

\newcommand{\kw}[1]{{\small\texttt{#1}}}
\newcommand{\lilemail}[1]{\email{\small #1}}



\title{Ground: A Unified Framework for Data Context at Scale }
% \title{Grounding Data Context Through Big Metadata  }
% \title{Grounding Big Data with Data Context Services}

\numberofauthors{8}
\author{
% 1st. author
\alignauthor
Joseph M.\ Hellerstein\\
      \affaddr{Berkeley}\\
      \lilemail{AuthorEmail@gmail.com}
% 2nd. author
\alignauthor
Vikram Sreekanti\\
      \affaddr{Berkeley}\\
      \lilemail{AuthorEmail@gmail.com}
% 3rd. author
\alignauthor
Joseph E. Gonzalez\\
      \affaddr{Berkeley}\\
      \lilemail{AuthorEmail@gmail.com}
\and  % use '\and' if you need 'another row' of author names
% 4th. author
\alignauthor
Akon Dey\\
      \affaddr{Awake Networks}\\
      \lilemail{AuthorEmail@gmail.com}
% 5th. author
\alignauthor
Mark Donsky\\
      \affaddr{Cloudera}\\
      \lilemail{AuthorEmail@gmail.com}
% 6th. author
\alignauthor
Sreyashi Nag\\
      \affaddr{University of Delhi}\\
      \lilemail{AuthorEmail@gmail.com}
\and
\alignauthor
Krishna Ramchandran\\
    \affaddr{FICO}\\
    \lilemail{AuthorEmail@gmail.com}
\alignauthor
Chang She\\
    \affaddr{Cloudera}\\
    \lilemail{AuthorEmail@gmail.com}
\alignauthor
Carl Steinbach\\
    \affaddr{LinkedIn}\\
    \lilemail{AuthorEmail@gmail.com}
}

\maketitle

\begin{abstract}
Ground is an open-source \emph{data context service}; a system to manage all the peripheral information that informs the use of data. 
\joey{I know we keep referring to the technology as a service but perhaps the paper should refer to it as a framework?}
The way we use data has changed both philosophically and practically in the last decade, creating an opportunity for new data context services to foster further innovation in Big Data systems and applications. 
We provide motivation and design guidelines, present our initial design of a common metamodel and API, and explore the current state of the storage solutions that could serve the needs of a data context service. 
Throughout, we highlight opportunities for new research and engineering solutions.
\end{abstract}

\section{From Crisis to Opportunity}
\vikram{Like we talked about yesterday, should we flip this and talk about the traditional database stack instead of introducing big data first?}\akon{I think so too. It is widely accepted that traditional systems handle this well. However, this is not just a Big Data issue.}
% \joey{I see where everyone is coming from but I think the story is stronger if we focus on the limitations of data management in the ``big data''/``data lake'' worlds.}
The open-source Big Data movement, spearheaded by Hadoop, is often discussed in terms of changes in usage. This includes the ``three V's'' of Volume, Velocity and Variety of data being captured, and the agile working style typified by ``schema-on-use'' and a wide diversity programming models.

% Much less widely discussed is a 
A driving force behind this proliferation of Big Data technologies is the
% profound 
shift towards highly decoupled data systems. 
Traditionally, data systems were often designed by a single vendor and deployed as monolithic stacks spanning data ingest, storage, retrieval, and governance.
% regardless of how well-factored they were under the covers. %\msd{Although} 
A traditional DBMS included a consistent storage engine, a metadata catalog, a dataflow engine, a language compiler and optimizer, an execution scheduler/runtime, and facilities for data ingest and queueing all designed to work closely together.
 %\msd{, it was simply seen as a DBMS}. 
By contrast, in today's Big Data stack, nearly all of these components are explicitly independent and interchangeable with very narrow APIs.
% swappable, with multiple choices in wide use today. 
This decoupled architecture has enabled substantial innovation and specialization by fostering competition both in technology and price.
% specialization 
% % driving much of the excitement around big-data, 
% and has been embraced by both developers and customers.

\subsection{Crisis: Big Metadata}

An unfortunate consequence of the disaggregated nature of contemporary data systems
% architecture
% One negative side-effect of this diversity
is the lack of a standard mechanism
% for shared metadata 
%\msd{metadata or data context?} 
% for these independently designed components 
to assemble a collective understanding of the origin, scope, and usage of the data they manage.
% metadata ``signature'' or ``paper trail'' of their content and behavior.
In the absence of a better solution to this pressing need,
% The current best solution to this pressing need 
% The only widely-deployed option 
% is the 
many have turned to the 
Hive Metastore, which serves simple relational schemas---a dead end for representing the Variety of Big Data. 
As a result, most ``Data Lake'' projects lack 
even the most rudimentary information about the data they contain or how it is being used. 
% their components' behavior.
% ; it is often not even possible to discover what is being stored, much less how to manage it intelligently. 
For emerging Big Data customers and vendors, this \emph{Big Metadata} problem is hitting a crisis point.  

Two significant classes of end-user problems follow directly from absence of mechanism to manage meta-data.
%\jmh{Funny transition from software stack problem to usage problem. Need to start with interoperability and grow from there, or change preceding paragraph to focus on usage not the stack.}
%\joey{What are the problems? Could we introduce the ``Vs'' of meta-data management: Discovery, Provenance, Attribution, Context ..., if we could articulate these clearly then we could perhaps translate their implications on administration, loss-of-value, risk to organization, ... }
The first is poor productivity.
%The promise of the Data Lake is that a diversity of data can be easily captured, and then harnessed by analysts for value. 
% In the absence of metadata,
Analysts are often unable to discover what data exists, much less how it has been previously used by peers. 
As a result valuable data remains unused
% opaque, 
and human effort is routinely duplicated---particularly in a schema-on-use world with raw data that requires preparation.  
% for use.
``Tribal knowledge'' is a common description for how organizations manage this productivity problem. 
This is clearly not a systematic solution, and it scales very poorly as organizations grow.

The second problem 
stemming from the absence of a system to track meta-data 
is governance risk. 
Data management necessarily entails tracking or controlling who accesses data, what they do with it, where they put it, and how it gets consumed downstream. 
%In some cases this governance metadata is used to enforce policy (e.g.\ access control for Personally Identifiable Information); in others it is logged to support audits for compliance (e.g.\ in the Basel Committee on Banking Supervision). 
In the absence of a standard place to store metadata and and answer these questions, it is impossible to enforce policies and/or audit behavior. 
As a result, many administrators marginalize their Big Data stack as a playpen for non-critical data, and thereby inhibit both the adoption and the potential of new technologies.

% In our diverse experiences in industry, the authors 
\joey{I think we should drop this paragraph.  This paragraph is only our personal assessment of our credibility which is hard to trust.}
Through our experiences deploying and managing big data systems we 
have seen a pressing need for a common service layer to let Big Data components capture, publish and share metadata information in a flexible way. 
The effort in this paper began by addressing that need.

\subsection{Opportunity: Data Context}
The lack of meta-data services in the Big Data stack is both a modern crisis
but also an 
% clean-slate 
opportunity to rethink how we manage meta-data.
Storage economics and schema-on-use agility suggest that the Data Lake movement could go much farther than Data Warehouses in enabling diverse, widely-used central repositories of data that can adapt to new data formats and rapidly changing organizations.
In that spirit, we advocate rethinking traditional metadata in a far more comprehensive sense. 
More generally, what we should strive to capture is the full \emph{context} of data.

To emphasize the conceptual shifts of this \emph{data context}---and as a complement to the ``three V's'' of Big Data---
we introduce the \textbf{ABCs of Data Context}, each of which represents a major change from the simple metadata of traditional enterprise data management.

% \msd{not sure where some of these metadata items would fit in: (1) business metadata (keywords, classification, compliance details, end-user tags), (2) operational metadata (date and execution details), (3) etc. - perhaps a bullet point list of the types of metadata and how it fits into ABC categories might help. I'm not sure that ABC covers the full scope.
% }
% \jmh{Took a crack at making sure these could fit in. See discussion after the list about whether to be explicit here.}

% \jmh{Want to make sure that we get each of A, B and C to have simple stories about what's novel. Right now it's in notes; ideally we find a paragraph structure where it fits into each paragraph neatly. Or we could have a separate table...}

\vikram{``Change context'' sounds weird to me. Instead of calling each one context, can we say the ABCs of data context are application metadata, behavior and usage, and change over time? (or something like that). NOTE: Tentatively changing them. Leaving this here if we want to change back.}

\smallitem{A: Application Metadata}: This is the core information that describes how raw bits get interpreted for use. 
In modern agile scenarios, application context has changed significantly to be relativistic (many possible schemas for the same data) and complex (with custom code for data interpretation). 
Application context ranges from basic data descriptions (encodings, schemas, ontologies, tags), to statistical models and parameters, and user annotations.  
%Application context today is often bespoke, specific to a single use case or set of use cases. But some application context is intended to be universally applied; e.g., access control or privacy information. Note that the interpretation of raw data typically requires executing code. 
All of the artifacts involved---transformation scripts, view definitions, model parameters, training sets, etc.---are critical aspects of application context. 
%\jmh{Novelties: subjectivity of models, inclusion of richer detail including code.}
% Application context includes both metadata and code.

\smallitem{B: Behavioral \& Usage}: This is information about how data was created and used over time. 
In decoupled systems, this lineage information typically spans multiple technologies and formats and often originates from high-volume sources (e.g., machine-generated logs and sensors).
% It comes from a diverse set of applications, languages and compute frameworks, varying in granularity and interpretability.
Not only must we track upstream lineage,
% of a particular data object: 
the data sets and code that led to the creation of the data object, but we must also track the 
% It includes any
downstream lineage including the data products that were derived from this data object. 
Aside from data lineage, behavioral context includes logs of usage: the ``digital exhaust'' left behind by computations on the data. 
As a result behavioral context meta-data can 
% grow to be extremely large: often 
often be larger than the data itself. 
% \jmh{Novelties: diverse forms of lineage, high-volume log data,}

\smallitem{C: Change Over Time}: This is information about the version history of data objects over time, including changes to both the structure and content of the objects. 
Traditionally, meta-data has focused on the present, but historical context is increasingly useful in modern agile organizations.
This context can be a linear sequence of versions, or it can encompass branching and concurrent evolution of objects including code and data along with the interactions between co-evolving versions.
% across alternate versions, followed optionally by subsequent merges. 
While complex version history is familiar in the world of code, but here, we want to track it for all kinds of data objects: code, atomic data items, and collections of data as well. 
%\jmh{Novelties: versioning across both code and data, including singletons and collections.}
% If we view metadata more broadly, could a unified solution address a much broader set of goals than Data Warehouses? We can explore that notion along three axes:

% \smallitem{Data.} A schema-on-use world is inherently relativistic. Data does not have \emph{inherent} structure and meaning; rather, the structure is imposed post hoc---sometimes for general usage, sometimes for a specific task.  This means that the ``description'' of a collection of data depends not only on its original form, but on the (many) ways it is transformed for use over time.  

% \smallitem{Code}. Data is transformed by code, which becomes a necessary aspect of data description. Transformation is only one kind of data-centric code. There is also code that produces new data: analysis routines, statistical models, and outbound services like recommenders and ad systems. Data \emph{lineage} is a natural byproduct of code, relating it to data sources and outputs. Code also brings along data of its own: training data, model parameters, configuration files, etc. This is not the data of record in an organization; it is an aspect of the code itself. Code management brings its own requirements, notably information on versions, authors and testing.  
% %With code and data versioned over time we can envision robust reproducibility of experiments---a feature of interest in areas including hypothesis testing (e.g. A/B tests) and in scientific verification.  

% \smallitem{Usage}. In modern agile analytic environments, iterations of exploration, experimentation and (re)deployment of automated pipelines are daily activity. Ironically, today's Big Data software is not well-designed for enabling analysis of its own use. If people learn by doing, then the tribal knowledge of an analytic organization should be visible in its usage logs. Intelligent analytic software could take great advantage of these logs to augment and accelerate human activity and intelligence. Like all software usage logs, analytics logs are themselves big, diverse data.

\smallitembot
% \jmh{Having written the below, I'm not sure this is a good idea to discuss here. My concern here is that in neatly covering all the old stuff we're diminishing the contrast. The Three V's are a mnemonic for ``what's different''---even if you don't really believe them!  Maybe this should go in Related Work. It should also be looked over by an ex-Informatica or ex-WebSphere person.}
%\msd{I've re-read this section numerous times and feel that it doesn't fully capture the extent of motivation for this work that you've discussed very clearly in your live presentations. Perhaps this is best displayed as a graphic that shows the limited set of problems solved by the legacy approach to metadata juxtaposed with the expanded set of problems that can be solved by by data context; i.e., more clearly emphasize the delta (compliance: tracking access holistically, capturing data movement holistically, maintaining traceability of calculations; productivity: finding, trusting, and using data sets, eliminating data redundancy.}

We believe that data context services are both an exciting opportunity for the database community, and an urgent requirement for the field.
In the remainder of the paper we illustrate the opportunities in this space, design requirements for solutions, and our initial efforts to tackle these challenges in open source.
% The enhanced functionality needed for this layer of the modern Big Data stack goes well beyond traditional metadata management. We refer to it as \emph{Data Context} services. Context refers to the full gamut of peripheral information that informs your analysis: what data and code do you have, where is it stored, when does it get used, who knows about it, and how does it change over time?  


\section{Ground: Scenarios and Design}
We are building an open-source data context service we call \emph{Ground}, to serve as a central model, API and repository for capturing the broad context in which data gets used. 
Our goal is to address practical problems for the Big Data community in the short term and to open up further opportunities for research and innovation.

% \jmh{can chop}
% Data Context can assist with many goals in a multi-user, data-driven organization. For example, it can be used to assess end-to-end data quality validation for complex workflows; it can form the basis of experiment management and reproducibility; it can help smooth research-to-production data science lifecycles via sharing of code and data products; it can enable sensitive data to be tracked across programs and users in an organization; and it can be used to gather data and performance statistics that can be used by components to optimize their decisions. 

To illustrate the potential of the Ground data context service, we describe a realistic scenario in which Ground 
% a data context service 
is used to aid in data discovery, facilitate better collaboration, protect confidentiality, help diagnose problems, and ultimately enable new value to be captured from existing data.
% inspired by our interaction with analysts and data-scientists at major organizations.  
% based on a real use case. \vikram{Kind of weird to say customer here? Customer of whose / of what?} \akon{real world use case may sound better} 
After presenting the scenario, we explore the design requirements for a data context service.



\subsection{Scenario: Context Service Enabled }
\label{sec:scenarios}
% To illustrate the potential of Ground, consider the following scenario, based on a customer use case we have observed in the field.
% It is only modestly futuristic: there are applications that do some of these things today, but could do far more if they had access to broader context.

% \msd{I don't think the "moderately futuristic" disclaimer is necessary - it takes away the credibility of the example}

% \smallitem{Scenario 1: Intelligent Data Wrangling}\\
Janet is a 
%Customer Satisfaction
analyst at a large bank. 
She suspects that the social network behavior of customers can help predict which customers are likely to close their accounts (customer churn).
Janet has access to rich \emph{Ground context service enabled} data lake and a wide range of tools that she can use 
% a variety of applications 
to assess her hypothesis. 
%If she finds a strong signal, more technical data scientists in the bank can act on it to improve systems.
% Intelligent applications are emerging for each of these tasks today, which make suggestions to users. All could benefit from a more comprehensive service for data context, as we illustrate below.

Janet 
% plans to purchase a social media ``firehose'' feed for her analysis. To start, though, she 
begins by downloading a free sample of a social media feed.
She uses an advanced data catalog application (we'll call it ``Catty'') which connects to Ground 
% profiles that data 
and notifies her that the data lake has a very similar complete feed from the previous month. 
% Looking at that data, she finds it sufficient for her purposes; no need to pay for another feed. 
She then begins using Catty to search the lake for data on customer retention: what is available, and who has access to it?  
As Janet explores candidate schemas and data samples, Catty retrieves usage data from Ground and notifies her that Sue, from the data-science team, had previously used a database table called \kw{cust\_roster} as input to a python library called \kw{cust\_churn}.
% s previously joined one of them with weather data. After talking with her colleague, 
Examining a sample from \kw{cust\_roster} and knowing of Sue's domain expertise, Janet decides to work with that table in her own churn analysis.  
% In this scenario, the catalog application was particularly successful because it had access to broad context: not just a large corpus of raw data, but structured schemas for transformed versions of that data based on prior (schema-on-)use, as well as usage data capturing relationships between users, data and actions.

Having found the data she needs, Janet begins to profile, clean and transform the data using a data preparation application (``Preppy''). 
The social media data is a JSON document; Preppy searches Ground for relevant transformation scripts and suggests unnesting attributes and pivoting them into tables.
% Recognizing location names in Janet's dataset, Preppy then consults a geo-reference dictionary in Ground, maps names to locations, and informs her that many locations in her data set are far from bank branches, and may be candidates for cleaning.
Based on code and usage information in Ground, Preppy then suggests to Janet that she can derive new columns from the text of the posts, using a sentiment analysis package that is widely used at the bank. 
Based on security information in Ground, Preppy warns Janet that certain customer attributes she is accessing are protected and may not be used for customer retention analysis.
% by her boss; 
% she masks them in the output. 
Finally, to join the social media names against the customer names, Preppy uses previous transformation scripts registered with Ground by other analysts to suggest standardized join keys to Janet.


Having compiled the desired data, Janet loads it into her BI charting tool and discovers a strong correlation between  customer churn and social sentiment. 
Janet use the ``share'' feature of the BI tool to send it to Sue; the tool records the share in Ground.


Sue has been working on a machine learning pipeline for automated discount targeting. Janet's chart has useful features, so Sue consults Ground to find the input data.
Sue joins Janet's dataset with her existing training data but discovers that her pipeline's prediction accuracy \emph{decreases}.  
Examining Ground's schema information for Janet's dataset, Sue realizes that the \kw{sentiment} column is categorical and needs to be pivoted into indicator columns \kw{isPositive}, \kw{isNeg}, and \kw{isNeut}. 
Sue writes a python script to transform Janet's data into a new file in the required format.
She trains a new version of the discount targeting model and deploys it to send discount offers to customers at risk of churning.
To ensure accurate future predictions, Sue registers her training pipeline including Janet social media feeds in the daily build; Ground is informed of the new code versions and service registration.

After several weeks of improved prediction performance, Sue receives an alert from Ground about changes in Janet's script; she also sees a notable drop in prediction accuracy of her pipeline. 
Upon examination, some social media messages no longer display any sentiment in Sue's table, because an upgrade to the sentiment analysis code now produces categories for which she doesn't have columns (e.g., \kw{isAngry}, \kw{isSad}, \ldots).
Sue uses Ground to roll back the sentiment analysis code in Janet's pipeline and re-run her pipeline for the past month.  
This fixes Sue's problem in test mode. 
Sue wonders if she can simply reinstate the older versions of Janet's scripts in deployment. Ground shows that other pipelines now depend upon the new version of Janet's scripts.  Sue calls a meeting with the relevant stakeholders to untangle the situation.


\joey{moved from before the scenario}
Many other important scenarios benefit analogously from data context, including experimental reproducibility in the sciences, forensic analysis in security auditing, and proactive maintenance and configuration of IT infrastructure. 


Throughout our scenario, the users and their applications benefited from global data context. 
The applications were able to introduce valued-added services using the stored ``tribal knowledge'': \vikram{Should we call this something instead of tribal knowledge? Isn't the point sort of that the knowledge is no longer tribal?} recommending datasets and code, identifying experts, flagging security concerns, notifying developers of changes, etc.
The users had far better contextual awareness of both technical and organizational issues than is possible today.
Many of these application features are not difficult to implement, but only work well with access to global context. 
Data context services make this possible, opening up opportunities for innovation, efficiency and better governance.




% What did we highlight?
% \begin{itemize}
%     \item data discovery: the feed and the customer data. application metadata.
%     \item expert-sourcing: application metadata
%     \item mapping recommendations: placename-to-geo
%     \item code recommendations: data wrangling steps, sentiment analysis routines, etc
    
%     \item security alerts: data masking
    
%     \item outlier detection/cleaning: geo-reference too far from the bank branches
%     \item entity resolution: social handles and customer names
    
%     \item backward provenance:  identifying cause of problem
%     \item forward provenance: identifying affected services ..
%     \item change detection/versioning/notification
%     \item impact analysis
% \end{itemize}









% While the data wrangling application could have made some of these suggestions based on intrinsic properties of the data being transformed, it benefited substantially from peripheral context on other datasets and scripts. 
% : reference data like geographic distributions of branches, repositories of data science routines, and the analytic context that the datasets being wrangled came from the data lake with security annotations. \emph{Would be nicer to get an analytic context about Janet's behavior.}

% Armed with a tidy table of hundreds of columns joined together, Janet opens her chosen BI charting application. She plans to cube the data set along various features of users and social media behavior, assessing churn rates in different categories. Given the richness of her wrangled table, the resulting number of potential charts is enormous. Fortunately her BI tool has automated features to recommend charts of interest. Using training data from many other analysts stored in the context service, the recommender focuses on breaking down the data on the custom, algorithmically-extracted sentiment scores and bank-specific entity features, as well as time and space; it omits customer names and the attributes marked confidential.  Janet notices a subcategory of posts with hate speech, and the BI tool enables her to highlight that category and store annotations on the related customers in the context service.
% Here again the BI tool benefits from broad context: lineage from the data wrangling application identifying algorithmic results, metadata on masking from the catalog tool, and training data on chart selection.
% ; these tools use intrinsic properties of their input data today~\cite{jeffheer}. To work better, they could benefit from the lineage of transformations that created their input---in our case recognizing the presence of social media data at the source, and recommending charts that were chosen for visualizing other outputs of social media datasets.
%If interesting patterns emerge in the data visualizations, the analyst may recommend decisions to the organization: e.g. to deploy customer service representatives to respond on social media, or to have the data science team incorporate social media feeds into more sophisticated predictive models for churn.

% Data context is critical to the ``intelligent'' applications that assist Janet through this process. 
% Some features save her time on the task she is directly attempting; others provide her contextual information outside her core task---algorithmic ``tribal wisdom''. While some of these features can be provided by current applications that save and learn from their own metadata, all of them benefit substantially from a broader context that spans across applications. Finally, note that Janet's work here is also being captured, so that analysts in future doing churn analysis can benefit from her work.

% \joey{ \textbf{old passage:}
% This frustrating narrative sadly reflects the reality of many data-scientists.  
% Data pipelines that begin and end it a range of data systems across an organization are common and often drive many of the core services. 
% These pipelines are the product of the evolution of data and code and are susceptible to changes in both.  
% Their interaction and development is hard to capture entirely in traditional code and data systems and often relies heavily on the collective wisdom of an organization.
% Sue, the data-scientist, must therefore spend a substantial amount of time trying to understand these complex relationships which can slow progress and introduce costly and difficult to diagnose bugs. 
% Moreover, with greater context, many of the problems Sue encountered would never have occurred and instead Sue could have devoted her time to building better models.   
% }

%Note the ad-hoc, cyclic dependencies in this ``pipeline'': the catalog tool depends on the schemas and sketches generated by users wrangling data (schema-on-use!), the wrangling tool depends on the catalog tool, the BI tool benefits from the lineage of wrangling scripts and populates annotations that can be surfaced back in the catalog.

% \emph{A number of new applications for data analysts have begun to capture data context and provide assistive intelligence as described above, but they currently have no way to share that information.  Hence the scope of their context is limited to what they see at their inputs. Broadly-adopted data context services are key to expanding the intelligence of these applications, harnessing data and computation to improve analyst productivity.}


% \jmh{\textbf{Idea 2: Model training and serving.  Joey to fill in? Or borrow a scenario from Johann's paper.} 
% % The previous example focused on relatively simple exploratory data analysis. 
% Data context can bring similar benefits to the kinds of predictive services that hardcore data scientists build and deploy live in modern hosted applications.  
% Large-scale predictive services like recommender systems and driving instructions rely on data scientists and engineers working in agile development cycles.  
% The services are based on serving results from models; the models themselves are periodically trained off of features extracted from data. Data and features evolve over time. 
% Meanwhile, there should be a virtuous cycle of model training, serving and experimentation.  
% Want to improve this cycle. 
% Want to be able to run new models on old traces (cite Johann's paper). 
% Want to incorporate new models in debug mode in production. 
% Want to be able to reward staff for improving models. 
% Want to reallocate staff when the benefit of experimenting with the model no longer justifies the effort.}

% \joey{Here is a rough stab at something from the status quo perspective.  I could easily rewrite this post Ground but in reality Ground would prevent these sort of problems in the first place \ldots}

% \smallitem{Scenario 2: NAME ME}\\
% Sue, a data-scientist at a major online social media organization, recently joined their news team to develop a more personalized targeting system.
% Sue begins by examining the code responsible for the news feed and discovers that it pulls content from several different HIVE tables \verb|user_fin| and \verb|ad_posts1| and relies the on the fields \verb|vis_2|, \verb|score3|, and \verb|features_2| when determining how content is ordered. 
% Sue is curious about the contents and meaning of this data and spends the next few days asking team members and running statistics.
% She discovers that the table is filled by a cron job created by an intern that is no longer with the company and that months of data are missing.
% % Her team warns her to be careful when changing these tables since other teams may depend on them.
% Upon examining the cron job, Sue realizes that these tables are constructed by applying a set of machine learning scripts that pull from other tables across the company and several of those tables are no longer being updated.
% She posts on internal forms and in a few days discovers that the contents in the stagnant tables had been re-factored into standard units and are now exported in a new social network storage system.
% Sue realizes that she can improve performance by simply updating the cron jobs but worries that changes may adversely affect others who depend on the data.  
% Again she posts on forums and waits for responses.
% After a few days without response, Sue pushes an updated version of the cron job and attempts to back fill the the \verb|user_fin| and \verb|ad_posts1| tables with updated units.

% Over the next few weeks the accuracy of the targeting system begins to decline.
% Concerned, Sue studies the machine learning code and after extensive testing realizes that the hyper-parameters were tuned for the old data which had been updated less frequently.  
% She adjust the hyper-parameters but performance continues to degrade.  
% She studies the data further and begins to question the features she is pulling from the new graph storage system which correlate closely with the errors in her predictions.
% After extensive discussions with adjacent teams she discovers that one of the statistical models used to populate the data in the new graph system had been pulling data from the tables she was updating resulting in a statistical feedback cycle. 

% This frustrating narrative sadly reflects the reality of many data-scientists.  
% Data pipelines that begin and end it a range of data systems across an organization are common and often drive many of the core services. 
% These pipelines are the product of the evolution of data and code and are susceptible to changes in both.  
% Their interaction and development is hard to capture entirely in traditional code and data systems and often relies heavily on the collective wisdom of an organization.
% Sue, the data-scientist, must therefore spend a substantial amount of time trying to understand these complex relationships which can slow progress and introduce costly and difficult to diagnose bugs. 
% Moreover, with greater context, many of the problems Sue encountered would never have occurred and instead Sue could have devoted her time to building better models.   






\begin{figure}[t]
\centering
\includegraphics[width=0.75\linewidth]{groundarch.pdf}
\caption{The initial architecture of Ground.}
\label{fig:arch}
\end{figure}
% \jmh{\textbf{Idea 3: A Pragmatic example in existing Hadoop workflows.  LinkedIn or Navigator customer story?}  Maybe take Idea 1 and make it less about assistive features, more about lost lineage across HDFS, Trifacta, Hive and Tableau?}

\subsection{Design Requirements}
% \jmh{Shift in tense needs addressing. Maybe a clearer transition.}
In a decoupled architecture of multiple applications and backend services, context serves as a ``narrow waist''---a single point of access for the basic information about data and its usage. It is hard to anticipate the breadth of applications that could emerge.
% However, the use of data context remains an open-ended design opportunity. 
Hence we were keen to focus on simple decisions today that could enable the success of new services and applications in future. 
To this end we were guided by Postel's Law of Robustness from Internet architecture: ``Be conservative in what you do, be liberal in what you accept from others''.  
Guided by this philosophy, we identified four central design requirements for a successful data context service.

\smallitem{Model-Agnostic.} For a data context service to be broadly adopted, it cannot impose opinions on metadata modeling. 
Data models evolve and persist over time: modern organizations have to manage everything from COBOL data layouts to RDBMS dumps to XML, JSON, Apache logs and free text. 
As a result, the context service cannot prescribe how metadata is modeled---each dataset may have different metadata to manage. 
This is a significant weakness in the Big Data stack today: the Hive Metastore captures fixed features or relational schemas; HDFS captures fixed features of files.  
A key challenge in Ground is to design a core metamodel that captures generic information that applies to all data, as well as custom information for different data models, applications, and usage.\akon{this is a limitation of traditional systems as well}
We explore this issue in Section~\ref{sec:metamodel}.
% \joey{This seems like a limitation of a context service if it cannot impose any assumptions on how data is organized. Too liberal in what you accept?  Maybe add a comment here why this is still going to be ok.}

\smallitem{Immutable.} Data context must be immutable; ``updating'' stored context is tantamount to erasing history. %Indeed, Postel's Law essentially dictates that we never discard information, lest somebody ask for it. 
There are multiple reasons why history is critical. 
The latest context may not always be the most relevant: We may want to replay scenarios from the past for what-if analysis or debugging, or we may want to study how context information (e.g., success rate of a statistical model) changes over time.
Prior context may also be important for governance and veracity purposes: we may be asked to audit historical behavior and metadata, or reproduce experimental results published in the past. 
This simplifies record-keeping, but of course it raises significant engineering challenges.  
%Mature storage solutions in the Big Data ecosystem do not support immutability and versioning natively. \vikram{I feel like a lot of peoples' first response to this is going to be "What about HDFS?" We may want to rephrase a little bit.} \jmh{Right. Need to address versioned data as well. More generally be careful about the bleed into data in the paper.}
We explore this issue in Section~\ref{sec:prototype}.

\smallitem{Scalable.} It is a frequent misconception that metadata is small. In fact, metadata scaling was already a challenge in previous-generation ETL technology. In many Big Data settings, it is reasonable to envision the data context being far larger than the data itself. Usage information is one culprit:  logs from a service can often outstrip the data managed by the service. Another is data lineage, which can grow to be extremely large
depending on the kind of lineage desired
~\cite{cheney2009provenance}.  Version history can also be substantial. 
%Of course it is possible to argue that various forms of context information should be managed as ``real data''.  Our main point here is that the use of a context service will encompass analyses and lookups over that information.  
We explore these issues in Section~\ref{sec:prototype} as well.

\smallitem{Politically Neutral.}  While not a design requirement per se, we note that any narrow-waist service like data context has to ``be Switzerland to be successful''.  
Customers will only adopt a central data context service if they feel no fear of lock-in; application writers will prioritize support for widely-used APIs to maximize the benefit of their efforts. 
% Vendor-centric metadata and governance solutions in this space have traditionally raised concerns on those fronts; this is perhaps one reason why the traditional Master Data Management vendors have not been successful in the Big Data market. 
It is important to note here that \emph{open source is not equivalent to political neutrality}; customers and developers have to believe that the project leadership has strong incentives to behave in the common interest. 
We return to this point in Section~\ref{sec:discussion}.

\smallitembot
These design requirements informed the architecture of Ground, and helped us scope an agile agenda with an initial implementation working today, and many opportunities for improvement and innovation going forward.

\section{Architecture of Ground}
\label{sec:arch}
Based on the requirements above, the Ground architecture is informed by Postel's Law of Robustness and the design pattern of decoupled components. At its heart is a foundational metamodel called \emph{Common Ground} with an associated \emph{Aboveground} API for data management applications like the catalog and wrangling examples above. The core functions underneath Ground are provided by swappable component services that plug in via the \emph{Underground} API. 
A sketch of the architecture of Ground is provided in Figure~\ref{fig:arch}.



\begin{figure}[t]
\centering
\includegraphics[width=0.75\linewidth]{layers.pdf}
\caption{The Common Ground metamodel. The central layer shows {\node}s (circles) and {\edge}s.  
Below are \kw{NodeVersion}s (small dots) corresponding to each \node, connected by \kw{EdgeVersion}s corresponding to each \edge.  
Above is an example of lineage (dark edges) among selected versions.}
% For simplicity, the figure omits \kw{VersionSuccessor} relationships between different \kw{LineageEdgeVersion}s at the top, and between \
% \kw{EdgeVersion}s in the bottom layer.
\label{fig:layers}
\end{figure}


\subsection{The Common Ground Metamodel}
\label{sec:metamodel}
\jmh{Vikram to review}
% \jmh{Pull in the practical motivation for each layer from the GDocs outline.}
Ground is designed to manage both the ABCs of data context and the design requirements of data context services.
It is based on a layered graph structure shown in Figure~\ref{fig:layers}: one layer for each of the ABCs of data context.
% In the spirit of robustness, the central construct is simple and flexible: a Application-centric \modelgraph $M$ of nodes and edges for describing data, flexible enough to admit a diversity of traditional data models.
% (relational, entity/relationship, hierarchical, network, semi-structured, linked, etc.) 
% Underneath that metadata graph is a Change-capturing \versiongraph $V$, which can track a variety of models 
% of revision history for individual objects and collections. Above the metadata graph is a 
% Behavioral \lineagegraph $L$ used to capture the lineage of how pieces of data are derived.

%%%%%%%%%%%

\subsubsection{{\Core}s: Change Context}
% \begin{figure}[ht]
% \begin{scriptsize}
% \begin{multicols}{2}
% % \lstinputlisting{scala/core.scala.txt}
% \end{multicols}
% \end{scriptsize}
% \caption{\Core metamodel in Scala.}
% \label{fig:core}
% \end{figure}
\vikram{Rewrote this section and flipped the order of definitions to avoid redundancy.}

The \core layer of Common Ground captures Change information: the ``C'' in the ABCs of data context. It
bootstraps the representation of all information in Ground, by providing immutable objects called {\thing}s. The evolution of each \thing is captured by a directed acyclic graph of {\version} objects. Change metadata itself is the only information in Common Ground that is not versioned; this is why it forms the base of the metamodel.


In more detail, we begin with the definition of a \thing, which is simply a unique ID and a \kw{VersionHistoryDAG}. 
\kw{VersionHistoryDAG}s capture the change history across versions of a \thing; they consist of a set of \kw{VersionSuccessor}s that form a DAG of {\version}s representing branches and merges.
\kw{VersionSuccessor}s indicate that one version is the descendant of another.
The atom of our metmodel is \version, which is simply a globally unique identifier; it represents an immutable version of some object. 
Type parametrization ensures that all of the \kw{VersionSuccessor}s in a given DAG link the same subclass of {\version}s together.

The \core layer is not exposed to Aboveground (user-level) services. 
Instead, it offers the base of an inheritance hierarchy that is exposed by the outer layers described below.

%\kw{VersionHistoryDAG}s capture the change history across versions; they consist of a set of \kw{VersionSuccessor} relations that form a DAG of {\version}s representing branches and merges of versions. 
% Scala traits for the \core are shown in Figure~\ref{fig:core}.  
%(i.e., R transitively points to all other items). 
% Versioning forms the \core of Common Ground for two reasons.  
% First, we believe that context services are required to support complete history. 
% Metadata is long-lived, and key to understanding the evolving history of data---e.g., for auditing, reproducibility, and debugging. 
% Moreover, given the shrinking costs of storage and the increasing value of understanding data, metadata history is a good investment.
% % \footnote{Ground's design does not preclude the possiblity of truncating version history as a matter of system management, e.g., if storage is limited or policy dictates that certain metadata be retired.}.
% Second, 


% The last element of our \core metamodel is the critical building block for the rest of Common Ground: the \thing. 
%At the base of the hierarchy are identified, versioned objects called {\thing}s.
%A \thing consists simply of a unique ID and a \kw{VersionHistoryDAG}.
% \joey{You really need to give me more for Item, its still a little abstract of a concept ...}
% As we will see in the next section, most of the metamodel will use {\thing}s to capture the immutable aspects of an object, and the associated {\version}s to capture changes 
% to the object.

% \jmh{Do we want an equivalent of \tag for \thing?}
 
% \joey{This is also confusing.  How is the inheritance hierarchy exposed outsid }
% From this point on, when we speak of {\thing}s and {\version}s, we will actually be referring to objects in the subclasses defined below that are visible above Ground.

\subsubsection{{\Mantle}s: Application Context}

% \begin{figure}[ht]
% \begin{scriptsize}
% \begin{multicols}{2}
% % \lstinputlisting{scala/mantle.scala.txt}
% \end{multicols}
% \end{scriptsize}
% \caption{\Mantle metamodel in Scala.}
% \label{fig:mantle}
% \end{figure}

% Our philosophy is that the metamodel should be designed in layers for
% simplicity and elegance. \core classes are shared and evolve in infrequent,
% regimented updates to maximize backwards compatibility. More detailed versions
% of the metamodel (including versions specific to use cases) are mapped onto
% simpler versions of the model. Our goal to find a balance between the
% simplicity and the expressivity of the metamodel and leave the rest up to the
% application using this metamodel.

% To illustrate this philosophy, we have developed a somewhat richer metamodel
% that can be imposed onto the aforementioned model.

The \mantle level of Common Ground presents the basic metamodel exposed above Ground: notably {\node}s, {\edge}s, and {\graph}s for representing metadata. 
% All of these objects and collections inherit from \thing, and hence are automatically versioned.   
% Scala traits for the Mantle are shown in Figure~\ref{fig:mantle}.
We choose graphs for flexibility: they can represent metadata from a wide variety of 
semistructured (JSON, XML) and structured (Relational, OO, matrix) data models.
% typically with strong constraints on the graph shape (e.g. $\mbox{databases} \rightarrow \mbox{tables} \rightarrow \mbox{columns}$). %(Figure~\ref{fig:relational}).  
In the spirit of ``schema-on-use'', Common Ground was designed to allow diverse metadata to be independently captured as ad hoc model graphs and integrated as needed over time.
% \begin{figure}[ht]
% \centering
% \begin{minipage}{0.4\textwidth}
% \includegraphics[height=2in]{json.pdf}
% \caption{A JSON document represented as a graph.  Note the nesting of JSON objects (key-value collections) in a tree shape of oval nodes, and lists as chains of rectangular nodes.}
% \label{fig:json}
% \end{minipage}
% \hspace{0.1\textwidth}
% \begin{minipage}{0.4\textwidth}
% \includegraphics[height=2in]{relational.pdf}
% \caption{A relational database with two schemas, represented as a graph.  Note the fixed schemas$\rightarrow$tables$\rightarrow$columns structure, and
% the ad hoc foreign key references at the leaves.}
% \label{fig:relational}
% \end{minipage}
% \end{figure}

The basic \mantle design consists of a user-extensible class hierarchy of matched pairs of \thing and \version subclasses: e.g., \node and \kw{NodeVersion}, \edge and \kw{EdgeVersion}, etc.
% These classes inherit from the \core model's \thing and \version classes respectively, imbuing a unique id as well as a \kw{VersionHistoryDAG} with each instance of $C$.  
% In turn, all {\version}s in a subclass like
% \kw{NodeVersion} are identified by a \kw{TVID} (Version ID) that stores
% both the ID of the corresponding \thing , and another \kw{VersionID}
% to distinguish the specific \version.  
% It is thus possible to determine {\thing}s
% from their {\version}s and vice versa.  
% \jmh{There is a 1-to-many constraint
% between {\thing}s and {\version}s.  Worth noting, and asserting somewhere in the
% code.} \vikram {We agreed that we didn't need actually add anything about this
% to the document, right?}
To allow customization, the \mantle allows the \version subclasses to be associated with
both ad hoc {\gtag}s (key-value pairs) and fixed {\structure}s containing a prescribed set of {\gtag}s. 
% {\version}s themselves are
% immutable, so this information has to be associated upon creation. 
{\version}s and {\gtag}s are immutable; a fresh
\version of the \thing is created whenever a tag or value is changed. By contrast, {\structure}s are {\thing}s and have associated \kw{StructureVersion}s to capture their evolution; {\version}s are (optionally) associated with a specific \kw{StructureVersion}, not a \structure.
% \jmh{I skipped over RichVersions for simplicity.}
% \jmh{Careful here with tags -- associated with Items or Versions or both?}\vikram{Right now just Versions, but we've talked about adding them to Items as well.}
  % {\tag}s refer to the {\version} that contains them; 
  %a \tag is uniquely identified by its \version and key.  
% , a new \version subclass (e.g. \kw{NodeVersion}) must be generated to hold the new {\tag}s, and linked as a successor into
% the \kw{VersionHistoryDAG} of the corresponding \thing\footnote{Logically,
% the new version would likely contain a copy of all the unmodified {\tag}s
% of the preceding version as well, though in an implementation this could be
% encoded more efficiently.}.  
% We also allow {\tag}s to be associated with {\thing}s, 
% enabling users to register immutable tags that apply to all versions of a \thing.  \jmh{Need to get 
% this into the code.}  
% Structured information is captured via a \structure, akin to a relational table schema or a C struct. (This class is a descendant of \thing, hence contains versions in the form of \kw{StructureVersion}s.) {\structure}s provide a prescribed metadata format
% consisting of a set of key-type pairs; each \version that references a given \kw{StructureVersion} 
% \emph{must} have {\gtag}s with the corresponding 
% keys and value types.

% Up to this point we have referred to types rather loosely.  Ground currently includes 
% a typical set of built-in atomic types common to most languages: booleans, characters, strings, and
% numerics.  For now most of these types are being taken from Scala; we will evaluate whether additional 
% atomic types (e.g. SQL's decimal type) need to be built in.  One important type that is specific to 
% Ground is the Uniform Resource Identifier, or \uri.  We will describe the use of {\uri}s in more detail in the next section.  As of now we have no plans for user-defined types in Ground, though we will revisit
% this decision as we progress.
% As noted above, basic {\version}s are simply unique identifiers.
% We define {\richversion}s, which can be augmented with {\gtag}s and \kw{StructureVersion}s.  Our main user-facing modeling classes inherit from \richversion to support customization.  In general, the immutable aspects of \mantle model objects are captured in a \thing subclass
% (e.g. \node), and the mutable aspects in the corresponding \richversion subclass (e.g.
% \kw{NodeVersion}).  


% These basic objects are quite simple, but they can be customized by attaching
% ad hoc \kw{Attributes} to their versions: these are key/value pairs that can
% be attached to a specific \version. \jmh{Not clear from the Scala how you get attributes of a \thing!}
% Optionally, {\version}s can also have a \kw{Structure} that they impose: a set of attributes
% that they must contain.
% This more complex
% metamodel will simply be a composition of the building blocks we highlighted.
% The \mantle serves as the basis for increasingly rich, use-case specific forms of metadata that can be structured on top of this intermediate
% metamodel, benefiting both from the versioning embedded in the \core, and
% the typed graphical structure of the \mantle.

The most important \mantle subclasses provided with Common Ground are \node and
\kw{NodeVersion}, \edge and \kw{EdgeVersion} and \graph and
\kw{GraphVersion}, all defined in a straightforward manner.
% The \node, \edge and \graph classes contain no more information than the \thing superclass provides; similarly the 
% \kw{NodeVersion} class contains no more than \version.
% %, albeit in a publicly visible interface.
% % However, both the
% % \kw{NodeVersion} and \kw{EdgeVersion} classes augment their \version
% % superclass with an optional reference to a \kw{StructureVersion} (that we
% % will describe shortly) to represent a required structure for the version.
% By contrast, \kw{EdgeVersion}s add two \kw{NodeVersion} endpoints; \kw{GraphVersion}s contain a set 
% of \kw{EdgeVersion}s.  
% Like other properties of a \version, that set is immutable.  Hence a new 
% \kw{GraphVersion} needs to be generated to capture the \graph being modified by insertion,
% deletion, or update of an existing \kw{EdgeVersion}.

  % Working through the definitions of
% Figure~\ref{mantle} you can see straightforward definitions of \kw{Set}s
% and \kw{SetVersion}s, which inherit from \thing and \version.  The \graph
% class inherits from \kw{Set} without modification; the
% \kw{GraphVersion} class extends \kw{SetVersion}.

  % \jmh{For symmetry, we should probably rename \version to Version, and \thing to something else like a Item.} \jmh{We need a naming convention for these things to avoid the goo of discussing objects and versions in an ad hoc way.}


% In the \mantle metamodel, we have a number of objects that each extend the
% \kw{VersionedItem}. For each of object (say) ``\kw{Foo}'', there is a
% corresponding ``\kw{FooVersion}''
% class.
% These classes extend the \version class and compose the \kw{VersionHistoryDAG}
% for the objects that they represent.

% We also have collections of {\node}s and {\edge}s. In order to illustrate the
% design of these collections, let's consider the example of a \graph, which is
% represented simply by a set of {\edge}s. A \graph, just like all the other objects
% in the \mantle, is a \thing. 
% Versions are more complex for a collection type like {\graph} than for scalar types like \node or \edge.
% A \graph's version can change in two different ways. The first is simple: when you add or delete an \edge from the \graph, you implicitly create a new
% version of the \graph container. The
% second is if the {\edge}s themselves are modified---in particular, when the
% endpoints of the \edge change, even though the identity of the edge may not\footnote{As a motivating example, consider an ``ownership'' \edge that represents the current owner of a file.  This fact does not change identity, it just links to a different principal as the owner, allowing us to track the ownership of that file over time.}. This second case poses an interesting challenge
% in terms of correctly propagating versioning changes. In order to solve this
% problem, every \thing has the capability of being ``watched''. That is,
% every object has a list of subscribers to which it publishes updates.
% In Ground, a \graph
% watches every one of its {\edge}s, and if an \edge is modified, then the \graph
% will also create a new version of itself with this \edge.  \jmh{This feels imperative.  Instead, how about a declarative description of a constraint: the version of a Graph relates in some way to the most recent version of any Edge it contains.  You could probably leave out the description of how this is achieved
% entirely.} \vikram{Maybe I'm not understanding what you mean by declarative
% here, but if you read up until the sentence that ends with "the identity of the
% edge may not, I think it describes the ways in which the identity of a graph
% depends on its edges. Beyond that, if we want to leave out a description of how
% we're accomplishing this, then we can just cut out everything after that,
% right? Or is there something else missing?}

\smallitem{External Items and Schr\"{o}dinger Versioning}\\
We sometimes need to represent items outside of Ground that should be tracked: canonical examples
include GitHub repositories and Google Docs. Ground cannot automatically track these items as they change.
They are represented in Ground by \kw{ExternalItem}s, with \kw {ExternalVersion}s that contain various tags: a \uri reference,  \kw{timestamp}, optional \kw{cachedValue}, and parameters for accessing the
reference (e.g., port, protocol, etc.) \vikram{We decided to remove these as standalone objects a while back. We instead just decided to have a concept of externality that was an add-on to existing objects. If what's here is the desired behavior, then I have some code to write. :-)}
% \kw{ExternalItem}s have an \kw{isUnchanging}
% flag, which, if enabled, is an indication that the external resource is expected to be
% immutable, and there should only be one \kw{ExternalVersion} associated.
% Note that this is advisory; if the actual reference changes, Ground will not be aware. 
% Hence
% (i.e., not \kw{isUnchanging}), 
Whenever a Ground client uses the Aboveground API to access an a \kw{ExternalVersion}, this results in Ground fetching the URI and generating a new \kw{ExternalVersion}, containing a new
\kw{VersionID}, an updated timestamp and possibly an updated cached value. We refer to this as a \emph{Schr\"{o}dinger} versioning scheme: each time we observe an \kw{ExternalItem} it changes. This allows Ground to track the \emph{perceived} history of an external object.

% In summary, the \mantle model provides a public, above-Ground interface for building application-specific 
% abstractions by customizing the optional and structured tags of nodes and edges, and laying them out in versioned graphs. 

\subsubsection{\Crust: Usage Context}
% \begin{figure}[ht]
% \begin{scriptsize}
% \begin{multicols}{2}
% % \lstinputlisting{scala/crust.scala.txt}
% \end{multicols}
% \end{scriptsize}
% \caption{\Crust metamodel in Scala.}
% \label{fig:crust}
% \end{figure}
The goal of the \crust layer is to capture usage information composed from the nodes and edges in the model graph.  
To facilitate data lineage, Common Ground depends on two specific items---
principals and workflows---that we describe here.
% These are the only two items in Common Ground that go beyond graph structure; they are fundamental to the semantic notion of lineage.

\kw{Principal}s (a subclass of \node) represent the actors that work with data:  users, groups, roles, etc. 
% \kw{Principal}s are particularly important in data governance
% because they are central to both auditing and
% enforcement of policies like access control.
% Note that \kw{Principal}s
% are {\node}s, and built while access rights and group membership can be represented as {\edge}s.
% {\structure}s would be particularly useful here because users would
% have some set of required information based on the identity \& authentication
% schemes being used. 
\kw{Workflow}s (a subclass of {\graph}) represent specifications of code that can be invoked. Both of these classes have associated \kw{Version} subclasses.
% \kw{Principal}s and \kw{Workflow}s
% are the only ``semantic'' metadata objects prescribed by Common Ground; the rest of the metamodel is 
%  structural and general-purpose.
Any Data Governance effort requires both of these classes: as examples, they are key to use cases involving
policy enforcement, off-line auditing and reproducibility.

% The second common semantic concept is \emph{workflow specification}.
% This sort of metadata is very important to critical use cases like reproducibility and auditing.
% Workflows are representable in terms of the graph
% structure of the \mantle model, but we chose to make them
% first-class citizens in the \crust of the Ground metamodel. These
% This is critical to use cases like reproducibility and auditing.

% \kw{Workflow}s
% can capture a sequence of \textit{ad hoc}, exploratory actions or a
% pre-defined sequence of actions. 

In Ground, lineage
is captured as a relationship between two {\version}s, the second of which is derived from the
first. This relationship is due to some process, either computational
(a workflow) or manual (via some principal). \kw{LineageEdgeVersion}s, which contain 
optional references to \kw{Workflow} and \kw{Principal} nodes, connect (possibly differently-typed) {\version}s. 
Note that \kw{LineageEdgeVersion} is not a subclass of \kw{EdgeVersion}; an \kw{EdgeVersion} can only connect two \kw{NodeVersion}s; a \kw{LineageEdge} can connect {\version}s from two different subclasses, including subclasses that are not under \kw{NodeVersion}.  For example, we might want to record that Sue imported \kw{nltk.py} in her \kw{churn.py} script; this is captured by a \kw{LineageEdge} between a \kw{PrincipalVersion} (representing Sue) and an \kw{EdgeVersion} (representing the dependency between the two files).  

Usage data is often generated by analyzing log files, code, and/or data, and it can become very large.
It is well known that lineage is sometimes best generated lazily on access~\cite{cheney2009provenance}; for such lazy evaluation, \emph{ephemeral} \kw{LineageEdgeVersion}s can be used to maintain the Ground lineage API without committing the (redundantly computed) \kw{LineageEdgeVersion}s to immutable storage. \vikram{I'm confused about what this is saying. It definitely doesn't exist in the code. :-)}

\subsubsection{Extension Libraries}
The three layers of the Ground metamodel are intended to be very general-purpose an non-prescriptive.
Hence, we expect Aboveground clients to extend the classes in the top two layers to capture their application semantics.  Users can define their own
customization of the Ground metamodel by subclassing {\node}/\kw{NodeVersion}, {\edge}/\kw{EdgeVersion}, \kw{Principal}/\kw{PrincipalVersion}, etc., and adding
custom {\structure}s and {\gtag}s.  \vikram{This is the opposite of what we've said in the past, where we don't expect subclasses? We said that subclasses happened via Structures.}
These can be packaged into libraries for common cases (e.g. a library for representing
relational database catalogs, or scientific collaborations, or the models of a typical application like those in Section~\ref{sec:scenarios}).

% The API for \groundwire is the subject of a separate document.

%%%%%%%%%%%

\subsection{Key Services}
Ground's functionality is backed by five decoupled subservices.  For agility, we are starting the project using existing open source solutions for each.  We anticipate that some of these will require additional features for our purposes. In this section we discuss these the role subservices and our initial choices of solutions, and we highlight some of the research opportunities we foresee.

\smallitem{Ingest: Insertion, Crawlers and Queues}.  Metadata may be pushed into Ground or require crawling; it may arrive interactively or in batches. 
% These kinds of services have been explored for data ingest, and only need modest modification for Data Context.  
The main issue is to decouple the systems plumbing of ingest from an extensible set of metadata and feature extractors.
To this end, ingest has both Belowground and Aboveground APIs. \vikram{Any reason we switched from underground to belowground?}
Context objects appear for ingestion into Ground via a Belowground queue API. As metadata arrives, Ground publishes notifications to the associated data via an Aboveground queue. ``Value-added'' Aboveground applications can subscribe to these events, fetch the associated data, and generate additional metadata asynchronously. For example, an agent can subscribe for notifications of file data, hand off the files to an entity extraction system like OpenCalais or DeepDive, and subsequently tag the Common Ground objects corresponding to the files with labels for the extracted entities.
% Interactive insertion of metadata needs to be supported efficiently by the metadata storage component; batch insertion should make use of queueing services to handle bulk delivery and bursty arrivals.  
% Passive insertion needs to be handled via a data crawler that can register metadata from external services with Ground, and see if 
We recently extended the Gobblin data ingest system to publish metadata for the objects it crawls (from 
sources like filesystems, databases, etc.) into Ground via the Kafka pub/sub system, which is made visible Aboveground. \vikram{Should we have this here or in our "State of the System" part? I think it makes more sense to keep them separate.}
Metadata feature extraction is an active research area in both industry and academia; we hope that commodity APIs for scalable, continuous data crawling and ingest will drive more adoption and innovation in this area. 
% Similarly, this is a rich area for industrial collaboration: the vendor-neutral aspect of Ground's plumbing should foster a healthy ecosystem of interoperable applications at higher levels.

\smallitem{Versioned Metadata Storage}.  Ground must be able to efficiently store and retrieve metadata with the full richness of the Common Ground metamodel, including flexible version management of code and data, general-purpose model graphs and lineage storage. 
% Ground also needs to reference external data and handle Schr\"{o}dinger versioning.  
While none of the existing open source DBMSs is targeted at this data model, one can implement it in a shim layer above many of them. We discuss this at greater length in Section~\ref{sec:perf} we examine a range of open-source DBMSs; as noted there, we believe this is an area for significant database research.

% Note that Ground is not intended as the primary interface for accessing the data that is referenced by metadata; Ground is expected to \emph{describe} external data and track it, not serve it.  Hence Ground's most basic requirement for external data is to know how to store a unique ID for each item it tracks, and return that ID to applications that request it.  In an ideal setting, each external data item is versioned, hence each version has a unique ID.  However if the external item is mutable and not versioned, Ground generates \emph{Schr\"{o}dinger versions} lazily: each time we observe an object we assume it changes, and assign it a new version (and version ID).  
% This is discussed in more detail in the Common Ground design~\cite{commonground}.

% \textbf{MVP:} We are currently mapping our metadata model onto a traditional PostgreSQL relational database for storage.  Graphs can be represented as relations, so we manage versions, lineage and data modeling graphs at application level above the relational model.  PostgreSQL is a fairly mature system but is not designed to meet our requirements for latency, scalability and availability. In fact we do not expect any relational solution to work well for our needs over time, as relational databases are not designed for any of the three key individual aspects of the metamodel: versioned data, polyglot data models, or rich lineage.  Unfortunately, we do not expect that solutions in the NoSQL or graph database world will fare well either, though this requires research to validate. Therefore a critical thrust of the Ground research agenda is to understand the weaknesses of existing database systems when faced with these requirements, and design a new database system that is well-suited to emerging metadata workloads. \jmh{Need to call out research hypotheses more clearly.}


\smallitem{Search and Analyze}.  Access to context information in Ground is expected to be complex and varied. As noted above, Common Ground supports arbitrary tags, which leads to a requirement for search-style indexing.
%; we plan to integrate Solr~\cite{solr} and ElasticSearch~\cite{elasticsearch}.  
Second, intelligent applications like those in Section~\ref{sec:scenarios} will run significant analytical workloads over metadata---especially usage metadata which could be quite large.  Third, the underlying graphs in the Common Ground model will require support for basic graph queries like transitive closures. Finally, it seems natural that some workloads will need to combine these three classes of queries.
%, perhaps via a federated query layer above them.  
As we also explore in Section~\ref{sec:prototype}, various open-source solutions can address these workloads at some level, but there is significant opportunity for research here.

% \textbf{MVP:} Initially we are not supporting search or analytic APIs; these will be added as the system evolves.  For interactive query, we can only do as well as our prototype relational metadata store.  For search, we expect that existing solutions like Solr will be sufficient for the foreseeable future; we do not expect metadata tagging and querying to exceed volumes that Solr sees in free-text indexing. For analytics, we intend to leverage Spark and GraphX as we have significant expertise in house.  However, the nature of the analytics to be done here represents a major research opportunity: what might be the value of metadata in a Big Data context, and how could that value be extracted by analytics?  Could a \emph{self-aware} Big Data ecosystem improve itself, or provide valuable insight about its usage to applications and users?  \jmh{Again, call out research.}  Finally, the requirements for a federated query layer and its design are a topic for investigation after we acquire a corpus of metadata and workloads.

% \textbf{MVP:}  Currently we are handling ingest solely via simple push insertion APIs that call into our metadata store via SQL.  However we envision integrating open-source solutions like Kafka for queuing, and Gobblin for crawling and data ingest from remote sources.  We are also eager to explore APIs to plug in third-party solutions for  extracting metadata from crawled data; two examples we are OpenCalais (a free automated service for entity extraction) and Trifacta (a commercial, semi-automatic solution for data transformation).  We also recognize that there are boundless R\&D opportunities here, some of which could be part of Ground, many of which should exist as standalone solutions above Ground.  \jmh{another research opening, though more about opportunities above ground.}  We look forward to integration with other research and non-research colleagues here.

\smallitem{Identity and Authorization Integration}.  Identity management and authorization are required to use the Ground service; interoperability is important here, as most organizations dictate a previously-chosen authorization service when adopting new technology.  More importantly, authorization is a semantic notion with wide flexibility: the policies of a federal defense agency are likely to be wildly different in nature from those of a corporate marketing department, which in turn differs from a consortium of scientists interested in reproducibility.  The flexible design of Ground's metamodel should support a wide variety of authorization metadata (ownership, auditing, content labeling etc.) and design policy over that metadata.  An open design question is whether Ground needs to \emph{enforce} policy, or merely store it and notify Aboveground applications.  As another open question, note the subtle challenges handling versioning across metadata and policy. Suppose the authorization policies of a past time are considered unsafe today---what should be done for users today who want to analyze past behavior? This is a case where good people may disagree about the virtues of immutability and reproducibility, and it's likely that most organizations would want to prevent version rollbacks in authentication policy. More research is required here.

% \textbf{MVP:}  The current MVP has no support for identity management and authorization.  However our initial use case has us tracking UC Berkeley student IDs, Github identities, UNIX uids from instructional computing, and associations between the three; visibility of things like grading scripts and their outputs will depend on policies regarding these identities.  In the short term we expect to integrate with Google oAuth services as exposed at UC Berkeley next, and to explore the way that policy is specified and possibly enforced in our prototpype environment.  Our longterm roadmap here remains open; we expect a need to collaborate closely with partners in application domains to get further requirements.  \jmh{Possible tie to Raluca's work here, at minimum as an example of a non-standard approach to these issues.}

\smallitem{Scheduling, Workflow, Reproducibility}. We are committed to ensuring that Ground is flexible enough to capture the specification of workflows at many granularities of detail: from black-box executables to workflow graphs to source code.  However, we do not expect Ground to be a universal provider of workflow execution or scheduling; instead we hope to integrate with a variety of schedulers and execution frameworks including on-premises and cloud-hosted approaches. This is currently under design, but the ability to work with multiple schedulers has become fairly common in the open source Big Data stack, so this may be a straightforward issue.

% \textbf{MVP:} We plan to begin by utilizing the scheduling and execution services provided by the Gobblin project, which supports a variety of schedulers including Quartz, Azkaban and Oozie, and execution frameworks including Yarn and Helix.  We plan to look into support for VMs and containers as well.  \jmh{Certainly could paint a research picture here, closer to the Bloom-meets-Kubernetes agenda: how will data-centric workflows be programmed in the future, especially as we look at containers, elastic services, etc?}  maybe also a connection to the Shenker/Jackson work on Declarative Datacenters?

\smallitembot
% \begin{figure*}[th]
% \center
% \includegraphics[width=0.7\linewidth]{groundarch.pdf}
% \end{figure*}

% \subsection{Common Ground: A Metamodel}
% \label{sec:metamodel}
% \subsection{Underground Services}

\section{Ground \MakeLowercase{v}0}
\label{sec:prototype}
% \vikram{I used prototype here as a placeholder, but I don't think we should call it that. Prototype sort of sounds like we built a thing and we're going to throw it away, whereas in reality, we have code that we're going to release as an Alpha in the next 2 months.}

% \subsection{State of the System}
Our initial version of Ground implements the data model discussed in Section~\ref{sec:metamodel} and provides a REST API that facilitates interaction with the system. 
As discussed in the previous section, it currently makes use of Gobblin for crawling and ingest and Kafka for queueing and pub/sub. 
We have integrated and evaluated a number of backing stores for versioned storage, including PostgreSQL, Cassandra, TitanDB and Neo4j; we report on results later in this section
% An integral part of our initial architecture has been evaluating different "state of play" backing stores. 
% In particular, Ground currently is compatible with Postgres, Apache Cassandra, TitanDB, and Neo4j. 
We are currently integrating ElasticSearch for text indexing, and are still evaluating options for ID/Authorization and Scheduling/Workflow. 

In addition to the basics of the system, we have three protoypical sources of data context integrated with Ground:

\smallitem{Relational Schemas: Hive Metastore.} The Hive Metastore provides relational schema support for the Hadoop stack.
As a part of our prototype, we have built a connector that allows Ground to serve as a drop-in replacement for Hive Metastore.
One key benefit of using Ground as Hive's relational catalog is Ground's built-in support for versioning, which---combined with the append-only nature of HDFS---makes it possible to ``time travel'' and view Hive tables as they appeared in the past.

\smallitem{Filesystem Metadata: HDFS} We have extended Gobblin to extract file system metadata from its HDFS crawls, and publish them Ground's Kafka connector. The resulting 
metadata is then ingested into Ground, and notifications are published on a Kafka channel for applications to respond to.
% This pipeline notifies us of any new files that are added to HDFS. 
% In addition, we are planning on adding hooks which allow Ground to call out to other services (e.g., a parser or featurizer that will extract additional metadata) that might be interested in new files. 

\smallitem{Code Versions: Git History.} Another key kind of metadata is code versions; as described in the introduction, code it key to understanding the meaning and usage of data.
Today, a great deal of code is versioned in git repositories.
% An integral part of tracking data usage effectively is understanding which code versions were used to transform or wrangle data. 
To that end, we have ingested version history graphs from git repositories into Ground.
\smallitembot


% These three use cases represent three very different kinds of metadata, exercising the flexibility of our model graphs and underlying storage. Git has a fairly rich versioning model, which exercises our version graphs. Together these use cases


\subsection{Use Cases}

\smallitem{Proactive Impact Analysis.} A common use case we envision for data context services is analyzing the effects of a code change on downstream services that depend on that code.
As a model for this use case, we constructed a dependency graph based on Java files in Apache Hadoop.
We perform impact analysis by running transitive closure starting from a particular version of a file and looking at every other file version on which it depends.

\smallitem{Dwell Time Analysis.} In the vein of the analysis Sue and Janet were doing in Section 2, our second use case was performing dwell time analysis.
To mock this use case, we sessionized the Star Wars Kid web log and mapped each session to a version of the Apache httpd web server.
We then retrieved the sessions that were connected to each version in order to enable dwell-time analysis. 
\\

While both these use cases are toy examples, both in scale and in actual functionality, we believe that they are accurate stand-ins for the larger and more ``real world'' use cases described. These use cases were the basis of our initial benchmarks.

\subsection{Initial Results}
\begin{figure}
\includegraphics[width=0.75\linewidth]{adjacent.png}
\caption{Figure 1.}
\label{fig:fig1}
\end{figure}

\begin{figure}
%\vspace{1in}
\includegraphics[width=0.75\linewidth]{trans_closure.png}
%\vspace{1in}
\caption{Figure 2.}
\label{fig:fig2}
\end{figure}

\begin{figure}
\vspace{1in}
The third graph goes here.
\vspace{1in}
\caption{Figure 3.}
\label{fig:fig3}
\end{figure}

\smallitem{Postgres.} The Postgres adjacency retrieval is a single-table look-up that is optimized with an index. 
The performance results here are expected and not noteworthy.

With the transitive closure query, we compared three different implementations. The first was a recursive query using the \kw{with} syntax. 
The second was a UDF written in PGPSQL that iteratively and semi-naïvely computed the paths that we were interested in. 
The last was a fully unrolled multi-table query that manually computed the paths of the longest possible length. From  the results, it is evident Postgres has a serious problem with graph processing.

\smallitem{Cassandra.} The Cassandra adjacency retrieval query was identical to the Postgres query: A single table look-up which was aided by an index.

The transitive closure was our pseudo-baseline. Instead of executing the query in Cassandra, we loaded the whole graph into memory and used the Java graph-processing library JGraphT to answer the query.

\smallitem{Neo4j} The Neo4j adjacency query was markedly slow for the first few queries (\kw{O(10 seconds)}), but subsequent queries became increasingly fast, presumably as data was cached in memory. Neo4j shone in the transitive closure scenario, performing as fast as the Java in-memory implementation. With both queries, performance was significantly bolstered by indexing the NodeVersion id that served as the starting point.

\smallitem{TitanDB.} TitanDB's adjacent query performance was ... 

The transitive closure query performed an order of magnitude slower than the Java in-memory and Neo4j implementations but was still significantly faster than any Postgres implementation.

\smallitembot

All benchmarks were run on a single Amazon EC2 \kw{m4.xlarge} machines with 4 CPUs and 16GB of RAM. 
These benchmarks were not meant to be exhaustive or representative of the performance of all graph processing systems. 
Rather, they represent initial evaluation of commonly used systems (i.e., ``state of play'') under simple versions of our workloads.
We acknowledge that with further tuning, these systems might perform better than they did in our experiments.

% \section{Discussion}
% \label{sec:discussion}
% \jmh{This may evolve into Research Opportunities or Future Work, but this is a placeholder for things that were postponed in earlier text}

% \jmh{Backref to Scalability discussion above, and the question ``are logs data or metadata''?}
% Functionality: well, we've started building out a few things and they went well.  Apiary and Grit.

% Performance: Here we ran into some bottlenecks with the widely-used storage systems in the field.  This merits more attention.

% \section{Challenges for the community}
% \label{sec:challenges}
% \jmh{May not be room for this. Instead find a way to call out the challenges in the body as they occur, with clear formatting.}

\section{Related Work}
\label{sec:relwork}
Work related to this paper comes in a variety of categories; for brevity we summarize the conceptual highlights here, and omit scholarly reference to software that's easily found on the web. More traditional references will be included in the final paper. 

Historical Master Data Management and ETL solutions are ill-suited to our domain; they were designed for maintaining invariants like data integrity and access control in a carefully curated world of enterprise applications, marts and warehouses. While this is unnatural in today's agile environments, it is interesting to consider what can be salvaged. Can curation invariants be inferred rather than authored? If they are ``soft'' invariants, how should software and organizations maintain them? What kinds of user experiences can blend the governance of traditional tools with the agility of ad hoc analytics?  This is an excellent opportunity for innovation. Meanwhile, readers familiar with these systems will be able to map them into parts of our ABCs of context: ``business'' metadata falls into Category A, while ``technical'' or ``operational'' metadata'' falls into both A (for system specs) and B (for usage and lineage).

There are a few notable recent systems that provide data context. OpenChorus and IBM LabBook offer end-user features for collaboration and social data analysis---exemplars of valuable AboveGround functionality.
LinkedIn WhereHows and Google Goods \jmh{to finish}.  By contrast, Ground is focused on the design of a shared services layer for a range of Aboveground applications to share in unanticipated ways. This raises the unique challenges and opportunities we are pursuing.

In the Big Data world, there are two emerging metadata service options that are targeting general-purpose use: Cloudera Navigator and Apache Atlas led by Hortonworks and their customers. Both of these are built on flexible graph metamodels that inspired the Common Ground \mantle; neither provides the \core versioning \vikram{version graph versioning sounds weird} we propose, and neither is perceived as a vendor-neutral option by customers.  Like us, these systems are also exploring ``underground'' alternatives for storage and querying, and we look forward to learning more from them on those topics. 

% Custom metadata stores have been open-sourced by LinkedIn (WhereHows) and FINRA (Herd); both of these are ``opinionated'' rather than general-purpose: specific to use cases in their organizations. They provide a good challenge for Ground, as examples of use cases to be supported. 

% Alation, Tamr, Waterline
% ReproZip, Burrito
% DeepDive, OpenCalais
% VizTrails
Finally, as noted in Section~\ref{sec:scenarios} there is a wide variety of Aboveground work in both research and industry on applications for particular kinds of context usage for cataloging, wrangling, and analyzing data. There are also many Aboveground commercial and research tools for extracting features and lineage, and providing visual interfaces to those specific information.
Today, these systems must track their own context and metadata, and have to implement point-to-point integrations with other applications and services. Our hope is that Ground will accelerate this activity and enable these applications to improve substantially in coming years.

% Postgres, DataHub, Datomic Pachyderm, Noms
In a final note, decades after the early work on the Postgres storage system, there is renewed interest in no-overwrite and versioned storage, including Datomic, DataHub, Pachyderm and Noms. In future work we plan to assess this space more deeply.

% including Big Data catalog applications (Alation, Tamr, Waterline), analytic lineage systems (ReproZip, Burrito), information extraction systems (DeepDive, OpenCalais, etc.) and so on. Our hope is for Ground to provide a widely adopted, interoperable subsystem for these applications, freeing them to focus on their own key technical differentiators in adding application-specific intelligence and user experiences.  Finally, there is a host of research on graph queries/DBs, and a much smaller body of work on immutable databases (Postgres, Datomic, Pachyderm.io, Noms); it is quite possible that those solutions could evolve to serve the needs of a context service like Ground.  \textbf{Mention VizTrails.}

% Readers familiar with 20th Century enterprise metadata products should recognize how terminology of that era fits into this broadened scope. ``Business metadata'' like compliance details, keywords, and classifications fall into Application context. Some ``technical metadata''  (configurations and scripts) fit into Application context; data lineage by contrast fits into Behavioral Context. ``Operational metadata'' regarding execution fits into Behavioral Context as well.

\section{Conclusion}
\label{sec:conclusion}
Data context services form a critical missing layer in today's Big Data stack, and deserve careful consideration given the central role they can play. They alos raise interesting challenges and opportunities spanning the breadth of database research. The basic design requirements---model-agnostic, immutable, scalable services---seem to present new database systems challenges Underground. Meanwhile the Aboveground opportunities for innovation cover a broad spectrum from human-in-the-loop applications, to machine learning pipeline development, to critical infrastructure for IT management. \akon{Does this include dataset life cycle management, backup, archival, deletion, etc.?} Ground is a community effort to build out this roadmap---providing useful open source along the way, and an environment where advanced ideas can be explored and plugged in.

\bibliography{ground}
\end{document}
